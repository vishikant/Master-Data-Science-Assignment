{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27609659-2c93-42ad-a893-d966c1ac1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### **Step 1: Create Project Folder and Initialize Git**\n",
    "\n",
    "1. **Create a folder for the project:**\n",
    "\n",
    "```bash\n",
    "mkdir ml_breast_cancer_project\n",
    "cd ml_breast_cancer_project\n",
    "```\n",
    "\n",
    "2. **Initialize Git:**\n",
    "\n",
    "```bash\n",
    "git init\n",
    "```\n",
    "\n",
    "### **Step 2: Set Up a Virtual Environment**\n",
    "\n",
    "3. **Create a virtual environment:**\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "```\n",
    "\n",
    "4. **Activate the virtual environment:**\n",
    "\n",
    "- On Windows:\n",
    "\n",
    "```bash\n",
    ".\\venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "- On macOS/Linux:\n",
    "\n",
    "```bash\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "### **Step 3: Create Folder Structure**\n",
    "\n",
    "5. **Create the project structure using Python:**\n",
    "\n",
    "Hereâ€™s a Python script to create the folder structure:\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Define the project structure\n",
    "folders = [\n",
    "    \"src\",\n",
    "    \"src/__init__.py\",\n",
    "    \"src/logger.py\",\n",
    "    \"src/exception.py\",\n",
    "    \"src/utils.py\",\n",
    "    \"src/components\",\n",
    "    \"src/components/__init__.py\",\n",
    "    \"src/components/data_ingestion.py\",\n",
    "    \"src/components/data_transformation.py\",\n",
    "    \"src/components/model_trainer.py\",\n",
    "    \"src/pipeline\",\n",
    "    \"src/pipeline/__init__.py\",\n",
    "    \"src/pipeline/predict_pipeline.py\",\n",
    "    \"src/pipeline/train_pipeline.py\",\n",
    "    \"src/import_data.py\",\n",
    "    \"src/setup.py\",\n",
    "    \"notebooks\",\n",
    "    \"notebooks/exploratory_data_analysis.ipynb\",\n",
    "    \"requirements.txt\",\n",
    "]\n",
    "\n",
    "# Create folders and files\n",
    "for folder in folders:\n",
    "    if folder.endswith('.py'):\n",
    "        open(folder, 'w').close()\n",
    "    else:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "```\n",
    "\n",
    "### **Step 4: Create `setup.py` and `requirements.txt`**\n",
    "\n",
    "6. **Write the `setup.py`:**\n",
    "\n",
    "```python\n",
    "# src/setup.py\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name='ml_breast_cancer_project',\n",
    "    version='0.1',\n",
    "    packages=find_packages(),\n",
    "    install_requires=[\n",
    "        'numpy',\n",
    "        'pandas',\n",
    "        'scikit-learn',\n",
    "        'flask',\n",
    "        'pymongo',\n",
    "        'matplotlib',\n",
    "        'seaborn',\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "7. **Write the `requirements.txt`:**\n",
    "\n",
    "```plaintext\n",
    "numpy\n",
    "pandas\n",
    "scikit-learn\n",
    "flask\n",
    "pymongo\n",
    "matplotlib\n",
    "seaborn\n",
    "```\n",
    "\n",
    "### **Step 5: Write Logging and Exception Handling Functions**\n",
    "\n",
    "8. **Write logging functionality in `logger.py`:**\n",
    "\n",
    "```python\n",
    "# src/logger.py\n",
    "import logging\n",
    "\n",
    "def configure_logging():\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"project.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "configure_logging()\n",
    "```\n",
    "\n",
    "9. **Write exception handling in `exception.py`:**\n",
    "\n",
    "```python\n",
    "# src/exception.py\n",
    "import logging\n",
    "\n",
    "class CustomException(Exception):\n",
    "    def __init__(self, message):\n",
    "        super().__init__(message)\n",
    "        logging.error(message)\n",
    "```\n",
    "\n",
    "### **Step 6: Create Import Data Functionality**\n",
    "\n",
    "10. **Load the breast cancer dataset into MongoDB:**\n",
    "\n",
    "```python\n",
    "# src/import_data.py\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def import_data_to_mongo():\n",
    "    # Load dataset\n",
    "    data = load_breast_cancer()\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cancer_db']\n",
    "    collection = db['breast_cancer']\n",
    "\n",
    "    # Insert data into MongoDB\n",
    "    collection.delete_many({})  # Clear existing data\n",
    "    collection.insert_many(df.to_dict('records'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_data_to_mongo()\n",
    "```\n",
    "\n",
    "### **Step 7: Data Ingestion**\n",
    "\n",
    "11. **Load the dataset from MongoDB:**\n",
    "\n",
    "```python\n",
    "# src/components/data_ingestion.py\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def load_data_from_mongo():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cancer_db']\n",
    "    collection = db['breast_cancer']\n",
    "\n",
    "    df = pd.DataFrame(list(collection.find()))\n",
    "    df.drop('_id', axis=1, inplace=True)  # Drop the MongoDB ID column\n",
    "    return df\n",
    "```\n",
    "\n",
    "### **Step 8: Data Transformation**\n",
    "\n",
    "12. **Implement feature engineering:**\n",
    "\n",
    "```python\n",
    "# src/components/data_transformation.py\n",
    "import pandas as pd\n",
    "\n",
    "def transform_data(df):\n",
    "    # Example: Normalize the data (standardization)\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    features = df.drop('target', axis=1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    return pd.DataFrame(scaled_features, columns=features.columns), df['target']\n",
    "```\n",
    "\n",
    "### **Step 9: Model Training**\n",
    "\n",
    "13. **Train a machine learning model:**\n",
    "\n",
    "```python\n",
    "# src/components/model_trainer.py\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from src.components.data_ingestion import load_data_from_mongo\n",
    "from src.components.data_transformation import transform_data\n",
    "\n",
    "def train_model():\n",
    "    df = load_data_from_mongo()\n",
    "    features, target = transform_data(df)\n",
    "\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(features, target)\n",
    "\n",
    "    # Example: Evaluate the model (for demonstration)\n",
    "    predictions = model.predict(features)\n",
    "    report = classification_report(target, predictions)\n",
    "    print(report)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "```\n",
    "\n",
    "### **Step 10: Create Jupyter Notebook for Analysis**\n",
    "\n",
    "14. **In the `notebooks` folder, create a Jupyter Notebook named `exploratory_data_analysis.ipynb`.** In this notebook, perform:\n",
    "   - **Exploratory Data Analysis (EDA):** Load the dataset, visualize features, and examine distributions.\n",
    "   - **Feature Engineering:** Handle missing values, scale features, etc.\n",
    "   - **Model Training:** Train models using different algorithms and compare performance metrics.\n",
    "\n",
    "### **Step 11: Set Up Flask for Deployment**\n",
    "\n",
    "15. **Create a basic Flask app for deployment:**\n",
    "\n",
    "```python\n",
    "# src/pipeline/predict_pipeline.py\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.components.data_ingestion import load_data_from_mongo\n",
    "from src.components.data_transformation import transform_data\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load model (this should ideally be done after training)\n",
    "model = RandomForestClassifier()  # Load or train your model here\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json()\n",
    "    df = pd.DataFrame(data)\n",
    "    features, _ = transform_data(df)\n",
    "    predictions = model.predict(features)\n",
    "    return jsonify(predictions.tolist())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "### **Step 12: Push to Git Repository**\n",
    "\n",
    "16. **Add files to Git and push changes:**\n",
    "\n",
    "```bash\n",
    "git add .\n",
    "git commit -m \"Initial commit of ML project structure and files\"\n",
    "git remote add origin <your_github_repo_url>\n",
    "git push -u origin master\n",
    "```\n",
    "\n",
    "### **Step 13: Add Additional Files from GitHub**\n",
    "\n",
    "You can manually download and add `README.md`, `LICENSE`, and `.gitignore` files to your project. Be sure to include necessary information in the `README.md` and specify files/directories to ignore in the `.gitignore`.\n",
    "\n",
    "### **Final Notes**\n",
    "\n",
    "This structure serves as a solid foundation for a machine learning project using the breast cancer dataset. You can expand upon the notebook with detailed exploratory analysis, train various models, and document your findings. Make sure to test the Flask API after completing the model training to ensure it works as expected.\n",
    "\n",
    "If you have any specific questions about any part of this process or need further assistance, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
